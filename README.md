# UnivBot

**UnivBot** is a full-stack AI-powered assistant built using **Next.js** and **Gemini API**, designed to provide a personalized, context-aware FAQ experience for college students. Users can upload documents (like handbooks, syllabi, or policies) or input custom information, and UnivBot will intelligently answer questions using that data.

---

## ðŸ”§ Core Concepts

### ðŸ§  Prompting

We use carefully crafted prompts to guide the Gemini model into understanding the user's intent. These prompts dynamically include context from the uploaded documents to improve relevance.

### ðŸ“Š Structured Output

The Gemini API is guided to return structured JSON responses using few-shot examples and prompt templates. This allows easy parsing and better UI rendering, such as categorizing answers or suggesting follow-ups.

### âš™ï¸ Function Calling

Geminiâ€™s function calling is leveraged for actions like:

* Fetching document metadata
* Summarizing uploaded files
* Searching relevant sections from stored user documents

Function definitions are passed into the prompt, and the model chooses when to invoke them.

### ðŸ” RAG (Retrieval-Augmented Generation)

UnivBot uses a basic RAG pipeline:

* Document chunks are stored and retrieved using similarity search (basic in-memory or local vector store).
* Retrieved chunks are injected into the prompt for Gemini, improving factual accuracy and contextual grounding.

---

## âš™ï¸ Implementation Stack

* **Frontend**: Next.js (App Router)
* **Backend**: Next.js API Routes
* **LLM**: Google Gemini API
* **File Upload**: Client uploads are parsed and chunked for context building

---

## âœ… Evaluation Criteria

### âœ”ï¸ Correctness

Answers are backed by user-uploaded or provided documents using Geminiâ€™s generation + RAG, ensuring factual accuracy.

### âš¡ Efficiency

Context retrieval and function calls are optimized using chunking and prompt templating to minimize latency and cost.

### ðŸ“ˆ Scalability

Built on Next.js API routes, the system can be easily scaled using Vercel or edge functions. Gemini API is highly scalable for inference.



---

### Zero-shot prompting 
â†’ Asking an AI to perform a task **without giving any examples**, only instructions.

### **Examples**

1. **Sentiment Analysis**
   *Prompt:* â€œIs this review positive, negative, or neutral?
   Review: *I love the new phone!*â€
   *Output:* `Positive`

2. **Language Translation**
   *Prompt:* â€œTranslate to French: I am learning AI.â€
   *Output:* `J'apprends l'IA.`

3. **Text Classification**
   *Prompt:* â€œClassify this: â€˜Bitcoin price hits \$70kâ€™ â†’ Options: Finance, Sports, Health.â€
   *Output:* `Finance`

---

### One-shot prompting 
â†’ You give the AI **one example** of the task before asking it to solve a similar problem.

### **Example**

**Prompt:**

```
Example: 
Input: "I love this movie!" â†’ Sentiment: Positive

Now, analyze this: 
Input: "The food was terrible." â†’ Sentiment:
```

**Output:**

```
Negative
```


---

### Dynamic prompting 
â†’ A technique where the **prompt changes automatically** based on **user input**, **context**, or **external data** to make AI responses more accurate and relevant.

### **Example**

**Scenario:** A travel chatbot.

**Prompt Template:**

```
User's location: {city}
Weather: {weather}
User: "Suggest me a place to visit."

AI Prompt (dynamic):  
"It's sunny in {city}. Suggest a good outdoor tourist spot."
```

**If city = "Delhi" & weather = "sunny":**

```
Output: "You can visit India Gate or Lodhi Gardens for a great outdoor experience."
```

---


### Multi-shot prompting
â†’ You give the AI **multiple examples** of how a task should be done before asking it to solve a similar problem. This helps the model understand the **pattern** better and improves accuracy.

### **Example**

**Prompt:**

```
Example 1:
Input: "I love this movie!" â†’ Sentiment: Positive

Example 2:
Input: "This food is horrible." â†’ Sentiment: Negative

Example 3:
Input: "The book was okay, nothing special." â†’ Sentiment: Neutral

Now analyze this:
Input: "The game was fantastic!" â†’ Sentiment:
```

**Output:**

```
Positive
```

---

### Chain-of-thought (CoT) prompting
â†’ A prompting technique where you ask the AI to **show its step-by-step reasoning** before giving the final answer. It helps the model solve **complex problems** more accurately.

---

### **Examples**

**1. Math Problem**
**Prompt:**

```
What is 25 Ã— 12? Think step by step.
```

**Output:**

```
25 Ã— 12 = (25 Ã— 10) + (25 Ã— 2) = 250 + 50 = 300.
Answer: 300
```

---

**2. Riddle Solving**
**Prompt:**

```
If John is older than Mary, and Mary is older than Sam, who is the oldest? Think step by step.
```

**Output:**

```
John > Mary > Sam.
So, John is the oldest.
```

---

**3. Word Problem**
**Prompt:**

```
A train travels 60 km in 1.5 hours. What is its average speed? Think step by step.
```

**Output:**

```
Speed = Distance Ã· Time = 60 Ã· 1.5 = 40 km/h.
Answer: 40 km/h.
```

---

### Embeddings
â†’ Numerical representations of text, images, or other data in a **high-dimensional vector space** where **similar items are close together**. Theyâ€™re used for **semantic search, recommendation systems, clustering, and NLP tasks**.

---

### **Examples**

**1. Semantic Text Search**

* Input: `"Best pizza places in Delhi"`
* Embedding model converts the query & restaurant descriptions into vectors.
* Finds the **closest vectors** â†’ returns most relevant pizza places.

---

**2. Document Similarity**

* Input documents:

  * Doc A: `"Machine learning improves AI."`
  * Doc B: `"Deep learning enhances artificial intelligence."`
* Their embeddings will be **close** â†’ meaning they're **semantically similar**.

---

**3. Recommendation System**

* If you liked `"Interstellar"`, the system finds movies with **embedding vectors** closest to `"Interstellar"` and recommends them.

---

### Cosine Similarity
 â†’ A metric used to measure **how similar two vectors are**, based on the **cosine of the angle** between them.

* Value ranges from **-1** to **1**:

  * **1** â†’ exactly similar (same direction)
  * **0** â†’ no similarity (orthogonal)
  * **-1** â†’ completely opposite

### **Example**

Letâ€™s say we have two vectors:

* **A = \[1, 2]**
* **B = \[2, 3]**

$$
\text{Cosine Similarity} = \frac{A \cdot B}{||A|| \, ||B||}
$$

**Step 1 â€” Dot product:**

$$
A \cdot B = (1)(2) + (2)(3) = 8
$$

**Step 2 â€” Magnitudes:**

$$
||A|| = \sqrt{1^2 + 2^2} = \sqrt{5}, \quad ||B|| = \sqrt{2^2 + 3^2} = \sqrt{13}
$$

**Step 3 â€” Cosine similarity:**

$$
\text{Cosine Similarity} = \frac{8}{\sqrt{5} \cdot \sqrt{13}} \approx 0.992
$$

**Interpretation:**
A and B are **very similar** because the cosine similarity is close to **1**.

---